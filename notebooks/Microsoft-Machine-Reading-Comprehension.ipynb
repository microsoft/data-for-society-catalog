{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas==1.3.5 matplotlib==3.5.2 numpy==1.19.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & Save training data file\n",
    "\n",
    "Download and save the 'train_v1.1.json' file from the below link and save it locally in the same folder as this notebook file.\n",
    "\n",
    "https://microsoft.github.io/msmarco/\n",
    "\n",
    "Then edit the json file and change the structure as follows to follow an array format:\n",
    "\n",
    "        _ add at the beginning and at the end of the content the symbols []\n",
    "\n",
    "        _ add a comma before each '{\"passages\"' (except the first match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('train_v1.1.json')\n",
    "\n",
    "# Total numbe of questions\n",
    "print(f\"Total number of questions is {len(df)}\")\n",
    "\n",
    "print(\"Inspect data structure\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening nested 'passages' list from JSON object\n",
    "\n",
    "# load data\n",
    "with open('train_v1.1.json','r', encoding=\"utf8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "# Flatten data\n",
    "df_nested_list = pd.json_normalize(data, record_path =['passages'])\n",
    "\n",
    "# To include query_id, query_type, query and answers\n",
    "df_nested_list = pd.json_normalize(\n",
    "    data, \n",
    "    record_path =['passages'], \n",
    "    meta=['query_id', 'query_type', 'query', 'answers']\n",
    ")\n",
    "\n",
    "df_nested_list.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique number of query types\n",
    "print(f\"Total number of query types is {len(df.query_type.unique())} - {(df.query_type.unique())}\")\n",
    "\n",
    "query_types = df[\"query_type\"].drop_duplicates().to_list() # get a sorted query types list removing duplicate values\n",
    "query_types_names = []\n",
    "query_types_total_questions = []\n",
    "for query_type in query_types:\n",
    "    query_types_names.append(query_type)\n",
    "    total_queries = (df[\"query_type\"] == query_type).sum()\n",
    "    query_types_total_questions.append(total_queries)\n",
    "    print(f\"'{query_type}' - total queries: {total_queries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3), subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "data = query_types_total_questions\n",
    "\n",
    "def func(pct, allvals):\n",
    "    absolute = int(np.round(pct/100.*np.sum(allvals)))\n",
    "    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n",
    "\n",
    "\n",
    "wedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data),\n",
    "                                  textprops=dict(color=\"w\"))\n",
    "\n",
    "ax.legend(wedges, query_types_names,\n",
    "          title=\"Query Type\",\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "\n",
    "plt.setp(autotexts, size=8, weight=\"bold\")\n",
    "\n",
    "ax.set_title(\"Training Dataset for reading comprehension and question answering - Number of questions per type\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c09002ab7c2936ab1ceb6a9c1f037dc584eff82d9a0aa3cc7e1742f8c8a4aac5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
